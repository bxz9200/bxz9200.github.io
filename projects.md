---
layout: page
permalink: /projects/index.html
title: Projects
---

# Research Projects
### Fully Attentional Networks with Self-emerging Token Labeling

![image](https://github.com/bxz9200/bxz9200.github.io/assets/36553004/5e5c5196-bed8-433e-ac5d-8ba44af5812b)

This is the project I worked on when I interned at NVIDIA. We proposed a novel training paradigm by using the self-emerging knowledge from Transformer-based models to improve the pre-training of ViTs. With only 77M parameters, our best model ranks top worldwide in the [leaderboard of various datasets](https://paperswithcode.com/paper/fully-attentional-networks-with-self-emerging#:~:text=Recent%20studies%20indicate%20that%20Vision,of%2Dthe%2Dart%20robustness.). I'm grateful to work with the amazing NV team, especially my manager [Jose M. Alvarez](https://alvarezlopezjosem.github.io/), my mentor [Zhiding Yu](https://chrisding.github.io/) and [Shiyi Lan](https://voidrank.github.io/).

