---
layout: page
permalink: /projects/index.html
title: Projects
---

# Research Projects
## Fully Attentional Networks with Self-emerging Token Labeling [[<font color=Blue>Paper</font>]](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.pdf)

![image](https://github.com/bxz9200/bxz9200.github.io/assets/36553004/5e5c5196-bed8-433e-ac5d-8ba44af5812b)

<div style="text-align: justify;">
<p>This is the project I worked on when I interned at NVIDIA. We proposed a novel training paradigm by using the self-emerging knowledge from Transformer-based models to improve the pre-training of ViTs. With only 77M parameters, our best model ranks top worldwide in the <a href="https://paperswithcode.com/paper/fully-attentional-networks-with-self-emerging#:~:text=Recent%20studies%20indicate%20that%20Vision,of%2Dthe%2Dart%20robustness.">leaderboard of various datasets<a>.</p> 
</div>

<div style="text-align: justify;">
<p>I'm grateful to work with the amazing NV team, especially my manager <a href="(https://alvarezlopezjosem.github.io/">Jose M. Alvarez<a>, my mentor <a href="https://chrisding.github.io/">Zhiding Yu<a> and <a href="https://voidrank.github.io/">Shiyi Lan<a>.</p>
</div>
<br>

---

## Clean-label Poisoning Availability Attacks [[<font color=Blue>Paper</font>]](https://ojs.aaai.org/index.php/AAAI/article/view/20902)

<img width="836" alt="image" src="https://github.com/bxz9200/bxz9200.github.io/assets/36553004/e8adf045-04cd-413e-a1b0-f2525975d6c4">

<div style="text-align: justify;">
<p>In this project, we proposed a clean-label attack that compromises the model availability. We used a GAN model with a triplet loss to generate stealthy and effective poisoned data.</p>
</div>

<br>

---

## Class-oriented Poisoning Attacks [[<font color=Blue>Paper</font>]](https://openaccess.thecvf.com/content/WACV2022/papers/Zhao_Towards_Class-Oriented_Poisoning_Attacks_Against_Neural_Networks_WACV_2022_paper.pdf)

[![Class-oriented Poisoning Attacks](https://img.youtube.com/vi/BFeutstPusk/0.jpg)](https://youtu.be/BFeutstPusk)

<div style="text-align: justify;">
<p>In this project we further advanced the adversarial goal of poisoning availability to a per-class basis. We control the model prediction for each class using COEG and COES attacks.</p>
</div>

